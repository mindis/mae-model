experiment_name: "desc__clean__cosine__frozen__no_unk"


data:
    img_dir: "/mnt/hd1/mumie-img"
    train_dir: "/mnt/hd1/mumie-json/final-cleaned/train"
    val_dir: "/mnt/hd1/mumie-json/final-cleaned/val-mini"
    test_dir: "/mnt/hd1/mumie-json/final-cleaned/test"
    desc_file: "./data/clean/desc.txt"
    attr_file: "./data/clean/attr.txt"
    value_file: "./data/clean/value.txt"
    vgg_ckpt: "./data/ckpt/vgg/vgg_16.ckpt"
    glove_ckpt: "./data/ckpt/glove-clean/embeddings.ckpt"
    av_ckpt: "./data/ckpt/av__clean__1024__cosine__no_unk/av.ckpt"
    attr_vocab_size: 1502
    value_vocab_size: 8662 # Remember: +1 for UNK
    desc_vocab_size: 458085


model:
    use_tables: False
    use_images: False
    use_descs: True

    trainable_attr_embeddings: False
    trainable_value_embeddings: False
    trainable_word_embeddings: False

    word_embedding_size: 200
    context_embedding_size: 1024
    fusion_method: "concat"
    distance_metric: "cosine"

    table_encoder_params:
        num_outputs: 2048
        dropout_keep_prob: 0.90
        phi_layers: 3
        phi_units: 2048
        rho_layers: 3
        rho_units: 2048

    image_encoder_params:
        num_outputs: 2048
        dropout_keep_prob: 0.50
        use_attention: False

    desc_encoder_params:
        num_outputs: 2048
        dropout_keep_prob: 0.50
        window_sizes: [3,5,7,9]
        num_filters: 1024
        fusion: "late"


training:
    batch_size: 16
    ckpt_dir: "data/ckpt"
    gradient_clipping: 0.5
    log_dir: "data/log"
    log_frequency: 100
    learning_rate: 0.0003
    max_desc_length: 1000
    max_number_of_images: 4
    max_steps: 10000000
    neg_sample_from_all_values: True
    neg_sample_from_attr_values: False
    neg_sample_unk: False
    pos_sample_unk: False
    random_seed: 1337
    sampling_method: "uniform"
    save_frequency: 10000

